{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89dee9-c9f7-4b34-8d31-1cfde6ad47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traitement de UCSDped1 ===\n",
      "Chargement des données...\n",
      "Construction du modèle...\n",
      "Début de l'entraînement...\n",
      "Epoch 1/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 302ms/step - loss: 0.1057 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - loss: 9.7655e-06 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 307ms/step - loss: 4.7167e-06 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 271ms/step - loss: 3.5128e-06 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 288ms/step - loss: 3.1483e-06 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - loss: 3.0180e-06 - learning_rate: 2.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - loss: 2.9966e-06 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 286ms/step - loss: 2.9789e-06 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - loss: 2.9635e-06 - learning_rate: 4.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 294ms/step - loss: 2.9625e-06 - learning_rate: 4.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - loss: 2.9574e-06 - learning_rate: 4.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - loss: 2.9549e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - loss: 2.9538e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 297ms/step - loss: 2.9525e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 310ms/step - loss: 2.9504e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 327ms/step - loss: 2.9497e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 340ms/step - loss: 2.9493e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 334ms/step - loss: 2.9499e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 284ms/step - loss: 2.9485e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 282ms/step - loss: 2.9453e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - loss: 2.9455e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 297ms/step - loss: 2.9450e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - loss: 2.9447e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 291ms/step - loss: 2.9420e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - loss: 2.9399e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 305ms/step - loss: 2.9400e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 289ms/step - loss: 2.9392e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 284ms/step - loss: 2.9381e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 285ms/step - loss: 2.9352e-06 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - loss: 2.9365e-06 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement terminé en 8.1 minutes\n",
      "Génération des visualisations...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step\n",
      "\n",
      "Résultats pour UCSDped1:\n",
      "- Seuil automatique: 0.0000\n",
      "- Visualisations sauvegardées dans /results\n",
      "\n",
      "=== Traitement de UCSDped2 ===\n",
      "Chargement des données...\n",
      "Construction du modèle...\n",
      "Début de l'entraînement...\n",
      "Epoch 1/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - loss: 0.1819 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - loss: 3.2780e-04 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - loss: 2.3907e-05 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - loss: 1.5809e-05 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - loss: 1.3886e-05 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - loss: 1.2645e-05 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - loss: 1.1729e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - loss: 1.1499e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 347ms/step - loss: 1.1261e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - loss: 1.1065e-05 - learning_rate: 4.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 293ms/step - loss: 1.1014e-05 - learning_rate: 4.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - loss: 1.0962e-05 - learning_rate: 4.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 290ms/step - loss: 1.0918e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 286ms/step - loss: 1.0903e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - loss: 1.0887e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 388ms/step - loss: 1.0871e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 389ms/step - loss: 1.0857e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - loss: 1.0841e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - loss: 1.0824e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - loss: 1.0805e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - loss: 1.0789e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 366ms/step - loss: 1.0771e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 363ms/step - loss: 1.0753e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - loss: 1.0735e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - loss: 1.0716e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 360ms/step - loss: 1.0697e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 316ms/step - loss: 1.0676e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 300ms/step - loss: 1.0656e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 308ms/step - loss: 1.0635e-05 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 320ms/step - loss: 1.0620e-05"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "# Configuration\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 128  # Augmenté pour accélérer l'entraînement\n",
    "EPOCHS = 30      # Réduit grâce aux optimisations\n",
    "\n",
    "def build_optimized_cae(input_shape=(64, 64, 1)):\n",
    "    \"\"\"Autoencodeur avec optimisation de l'architecture\"\"\"\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder optimisé\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer=Nadam(learning_rate=0.001), loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "def load_and_preprocess(dataset_path):\n",
    "    \"\"\"Chargement avec vérification et preprocessing accéléré\"\"\"\n",
    "    data = np.load(dataset_path).astype('float32') / 255.0\n",
    "    if len(data.shape) == 3:\n",
    "        data = data[..., np.newaxis]\n",
    "    return data\n",
    "\n",
    "def train_with_progress(model, X_train, dataset_name):\n",
    "    \"\"\"Entraînement avec callback de progression\"\"\"\n",
    "    start_time = time()\n",
    "    \n",
    "    # Callback pour réduire le LR dynamiquement\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=1e-5)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde rapide du modèle\n",
    "    model.save(f\"results/cae_{dataset_name}.h5\", save_format='h5')\n",
    "    \n",
    "    print(f\"\\nEntraînement terminé en {(time()-start_time)/60:.1f} minutes\")\n",
    "    \n",
    "    # Courbe de loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.title('Evolution de la Loss pendant l\\'entraînement')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"results/{dataset_name}_training_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "def visualize_reconstructions(model, X_test, dataset_name, n=10):\n",
    "    \"\"\"Visualisation améliorée des reconstructions\"\"\"\n",
    "    samples = X_test[:n]\n",
    "    reconstructions = model.predict(samples, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "        # Image originale\n",
    "        plt.subplot(3, n, i+1)\n",
    "        plt.imshow(samples[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Original\" if i == 0 else \"\", pad=10)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Reconstruction\n",
    "        plt.subplot(3, n, i+n+1)\n",
    "        plt.imshow(reconstructions[i].squeeze(), cmap='gray')\n",
    "        plt.title(\"Reconstruite\" if i == 0 else \"\", pad=10)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Différence\n",
    "        plt.subplot(3, n, i+2*n+1)\n",
    "        plt.imshow(np.abs(samples[i] - reconstructions[i]).squeeze(), cmap='hot')\n",
    "        plt.title(\"Différence\" if i == 0 else \"\", pad=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Comparaison Original/Reconstruction - {dataset_name}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/{dataset_name}_reconstructions.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def detect_and_visualize_anomalies(model, X_test, dataset_name):\n",
    "    \"\"\"Détection et visualisation des anomalies\"\"\"\n",
    "    # Calcul des erreurs\n",
    "    reconstructions = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    errors = np.mean(np.square(X_test - reconstructions), axis=(1, 2, 3))\n",
    "    \n",
    "    # Seuil automatique (95e percentile)\n",
    "    threshold = np.percentile(errors, 95)\n",
    "    \n",
    "    # Top 5 anomalies\n",
    "    top_anomalies = np.argsort(errors)[-5:][::-1]\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    for i, idx in enumerate(top_anomalies):\n",
    "        # Original\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        plt.imshow(X_test[idx].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Original {i+1}\\nErr: {errors[idx]:.4f}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Reconstruction\n",
    "        plt.subplot(3, 5, i+6)\n",
    "        plt.imshow(reconstructions[idx].squeeze(), cmap='gray')\n",
    "        plt.title(\"Reconstruction\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Différence\n",
    "        plt.subplot(3, 5, i+11)\n",
    "        plt.imshow(np.abs(X_test[idx] - reconstructions[idx]).squeeze(), cmap='hot')\n",
    "        plt.title(\"Différence\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Top 5 Anomalies Détectées - {dataset_name}\\nSeuil: {threshold:.4f}\", y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/{dataset_name}_top_anomalies.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def main():\n",
    "    datasets = {\n",
    "        'UCSDped1': {'train': 'UCSDped1_train.npy', 'test': 'UCSDped1_test.npy'},\n",
    "        'UCSDped2': {'train': 'UCSDped2_train.npy', 'test': 'UCSDped2_test.npy'}\n",
    "    }\n",
    "    \n",
    "    for name, paths in datasets.items():\n",
    "        print(f\"\\n=== Traitement de {name} ===\")\n",
    "        \n",
    "        try:\n",
    "            # Chargement accéléré\n",
    "            print(\"Chargement des données...\")\n",
    "            X_train = load_and_preprocess(paths['train'])\n",
    "            X_test = load_and_preprocess(paths['test'])\n",
    "            \n",
    "            # Construction et entraînement\n",
    "            print(\"Construction du modèle...\")\n",
    "            model = build_optimized_cae()\n",
    "            \n",
    "            print(\"Début de l'entraînement...\")\n",
    "            train_with_progress(model, X_train, name)\n",
    "            \n",
    "            # Visualisations\n",
    "            print(\"Génération des visualisations...\")\n",
    "            visualize_reconstructions(model, X_test, name)\n",
    "            threshold = detect_and_visualize_anomalies(model, X_test, name)\n",
    "            \n",
    "            print(f\"\\nRésultats pour {name}:\")\n",
    "            print(f\"- Seuil automatique: {threshold:.4f}\")\n",
    "            print(f\"- Visualisations sauvegardées dans /results\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur sur {name}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38f1c1-354d-4f85-a1fb-e00227e3ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
